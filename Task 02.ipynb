{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eace25bb-4554-43c9-8fca-b9fe340cbd20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Scraping BBC section: World (https://www.bbc.com/news/world)\n",
      " Scraping BBC section: Business (https://www.bbc.com/news/business)\n",
      " Scraping BBC section: Technology (https://www.bbc.com/news/technology)\n",
      "\n",
      " BBC News data saved to 'bbc_news_multigenre.csv'\n",
      "         Date         Headline  \\\n",
      "0  2025-11-02  Israel-Gaza War   \n",
      "1  2025-11-02   War in Ukraine   \n",
      "2  2025-11-02      US & Canada   \n",
      "3  2025-11-02               UK   \n",
      "4  2025-11-02      UK Politics   \n",
      "\n",
      "                                             Article  Genre  \n",
      "0  The bodies were identified as those of Amiram ...  World  \n",
      "1  Oleksandr Syrskyi says special forces have bee...  World  \n",
      "2  From hip-hop musician to the brink of running ...  World  \n",
      "3  Ten people are injured while police say the in...  World  \n",
      "4  The poor state of military housing has been a ...  World  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Define BBC sections to scrape\n",
    "sections = {\n",
    "    \"World\": \"https://www.bbc.com/news/world\",\n",
    "    \"Business\": \"https://www.bbc.com/news/business\",\n",
    "    \"Technology\": \"https://www.bbc.com/news/technology\"\n",
    "}\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for genre, url in sections.items():\n",
    "    print(f\" Scraping BBC section: {genre} ({url})\")\n",
    "\n",
    "    response = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Select article links\n",
    "    articles = soup.select(\"a[href*='/news/']\")\n",
    "\n",
    "    for a in articles:\n",
    "        headline = a.get_text(strip=True)\n",
    "        link = a.get(\"href\")\n",
    "\n",
    "        # Skip invalid links or non-articles\n",
    "        if not headline or not link or \"/av/\" in link or \"/live/\" in link:\n",
    "            continue\n",
    "\n",
    "        if link.startswith(\"/\"):\n",
    "            link = \"https://www.bbc.com\" + link\n",
    "\n",
    "        # Fetch the article text (optional but included for 'Article' field)\n",
    "        article_text = \"\"\n",
    "        try:\n",
    "            article_response = requests.get(link, headers={\"User-Agent\": \"Mozilla/5.0\"}, timeout=10)\n",
    "            article_soup = BeautifulSoup(article_response.text, \"html.parser\")\n",
    "            paragraphs = article_soup.select(\"article p\")\n",
    "            article_text = \" \".join(p.get_text(strip=True) for p in paragraphs)\n",
    "        except Exception as e:\n",
    "            article_text = \"Unable to retrieve article text.\"\n",
    "\n",
    "        all_data.append({\n",
    "            \"Date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "            \"Headline\": headline,\n",
    "            \"Article\": article_text,\n",
    "            \"Genre\": genre\n",
    "        })\n",
    "\n",
    "# Create DataFrame and save\n",
    "df = pd.DataFrame(all_data).drop_duplicates(subset=[\"Headline\"])\n",
    "df.to_csv(\"bbc_news_multigenre.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"\\n BBC News data saved to 'bbc_news_multigenre.csv'\")\n",
    "print(df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
